import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from scipy import stats
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler, LabelEncoder
import warnings

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾è¡¨é£æ ¼
sns.set(style="whitegrid")
plt.rcParams['font.sans-serif'] = ['SimHei', 'WenQuanYi Micro Hei', 'Heiti TC']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 300


class YChromosomeAnalysis:
    def __init__(self, file_path):
        self.file_path = file_path
        self.df = self._load_data()
        self.processed_data = None
        self.label_encoders = {}

        # æ¨¡å‹ç»“æœç¼“å­˜
        self.logreg_model = None
        self.rf_model = None
        self.predict_pass_rate = None
        self.feature_importance = None
        self.logreg_report = None

    def _load_data(self):
        """åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®"""
        try:
            excel_file = pd.ExcelFile(self.file_path)
            df = excel_file.parse('ç”·èƒæ£€æµ‹æ•°æ®')

            # æå–æ£€æµ‹å­•å‘¨çš„æ•°å­—éƒ¨åˆ†
            df['æ£€æµ‹å­•å‘¨æ•°'] = df['æ£€æµ‹å­•å‘¨'].str.extract('(\d+)').astype(int)

            # åªä¿ç•™å­•æœŸåœ¨ 10 å‘¨ - 25 å‘¨ä¹‹é—´çš„æ•°æ®
            df = df[(df['æ£€æµ‹å­•å‘¨æ•°'] >= 10) & (df['æ£€æµ‹å­•å‘¨æ•°'] <= 25)]

            # å¤„ç†æ•°å€¼ç±»å‹å­—æ®µ
            if 'æ€€å­•æ¬¡æ•°' in df.columns:
                df['æ€€å­•æ¬¡æ•°'] = pd.to_numeric(df['æ€€å­•æ¬¡æ•°'], errors='coerce').fillna(0).astype(int)
            if 'ç”Ÿäº§æ¬¡æ•°' in df.columns:
                df['ç”Ÿäº§æ¬¡æ•°'] = pd.to_numeric(df['ç”Ÿäº§æ¬¡æ•°'], errors='coerce').fillna(0).astype(int)

            # è®¡ç®— Y æŸ“è‰²ä½“æµ“åº¦æ˜¯å¦è¾¾æ ‡
            df['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'] = df['YæŸ“è‰²ä½“æµ“åº¦'] >= 0.04

            # æ¨¡æ‹Ÿæ£€æµ‹è¯¯å·®ï¼ˆæ ‡å‡†å·®ä¸ºå®é™…å€¼çš„5%ï¼‰
            np.random.seed(42)
            df['YæŸ“è‰²ä½“æµ“åº¦è¯¯å·®'] = df['YæŸ“è‰²ä½“æµ“åº¦'] + np.random.normal(0, 0.05 * df['YæŸ“è‰²ä½“æµ“åº¦'], len(df))
            df['YæŸ“è‰²ä½“æµ“åº¦è¯¯å·®è¾¾æ ‡'] = df['YæŸ“è‰²ä½“æµ“åº¦è¯¯å·®'] >= 0.04

            # å¤„ç†æ—¥æœŸå­—æ®µ
            if 'æœ«æ¬¡æœˆç»' in df.columns:
                df['æœ«æ¬¡æœˆç»'] = pd.to_datetime(df['æœ«æ¬¡æœˆç»'], errors='coerce')
            if 'æ£€æµ‹æ—¥æœŸ' in df.columns:
                df['æ£€æµ‹æ—¥æœŸ'] = pd.to_datetime(df['æ£€æµ‹æ—¥æœŸ'], errors='coerce')
                if 'æœ«æ¬¡æœˆç»' in df.columns and 'æ£€æµ‹æ—¥æœŸ' in df.columns:
                    df['æ€€å­•å¤©æ•°'] = (df['æ£€æµ‹æ—¥æœŸ'] - df['æœ«æ¬¡æœˆç»']).dt.days

            return df
        except Exception as e:
            print(f"æ•°æ®åŠ è½½é”™è¯¯: {e}")
            return pd.DataFrame()

    def feature_engineering(self):
        """ç‰¹å¾å·¥ç¨‹"""
        if self.df.empty:
            return

        self.processed_data = self.df.copy()

        # å¹´é¾„åˆ†ç»„
        age_bins = [0, 25, 30, 35, 40, float('inf')]
        age_labels = ['<25', '25-30', '30-35', '35-40', 'â‰¥40']
        self.processed_data['å¹´é¾„åˆ†ç»„'] = pd.cut(self.processed_data['å¹´é¾„'], bins=age_bins, labels=age_labels)

        # BMIåˆ†ç»„
        bmi_bins = [0, 18.5, 24, 28, 32, 36, float('inf')]
        bmi_labels = ['åè½»', 'æ­£å¸¸', 'è¶…é‡', 'è‚¥èƒ–I', 'è‚¥èƒ–II', 'è‚¥èƒ–III']
        self.processed_data['BMIåˆ†ç»„'] = pd.cut(self.processed_data['å­•å¦‡BMI'], bins=bmi_bins, labels=bmi_labels)

        # ç¼–ç åˆ†ç±»å˜é‡
        categorical_vars = ['IVFå¦Šå¨ ', 'æŸ“è‰²ä½“çš„éæ•´å€ä½“', 'èƒå„¿æ˜¯å¦å¥åº·']
        for var in categorical_vars:
            if var in self.processed_data.columns:
                le = LabelEncoder()
                self.processed_data[var] = self.processed_data[var].fillna('æœªçŸ¥')
                self.processed_data[var + '_ç¼–ç '] = le.fit_transform(self.processed_data[var])
                self.label_encoders[var] = le

        # åˆ›å»ºå¤åˆç‰¹å¾
        if 'èº«é«˜' in self.processed_data.columns and 'ä½“é‡' in self.processed_data.columns:
            self.processed_data['èº«é«˜ä½“é‡æ¯”'] = self.processed_data['èº«é«˜'] / self.processed_data['ä½“é‡']

        if 'æ€€å­•æ¬¡æ•°' in self.processed_data.columns and 'ç”Ÿäº§æ¬¡æ•°' in self.processed_data.columns:
            self.processed_data['æµäº§æ¬¡æ•°'] = self.processed_data['æ€€å­•æ¬¡æ•°'] - self.processed_data['ç”Ÿäº§æ¬¡æ•°']

        # åˆ›å»ºç»¼åˆé£é™©æŒ‡æ•°
        features_to_standardize = ['å¹´é¾„', 'å­•å¦‡BMI', 'æ£€æµ‹å­•å‘¨æ•°']

        additional_features = ['æ£€æµ‹æŠ½è¡€æ¬¡æ•°', 'æ€€å­•æ¬¡æ•°', 'ç”Ÿäº§æ¬¡æ•°']
        for feature in additional_features:
            if feature in self.processed_data.columns:
                features_to_standardize.append(feature)

        chromosome_features = ['YæŸ“è‰²ä½“çš„Zå€¼', 'XæŸ“è‰²ä½“çš„Zå€¼', 'GCå«é‡']
        for feature in chromosome_features:
            if feature in self.processed_data.columns and not pd.api.types.is_categorical_dtype(
                    self.processed_data[feature]):
                features_to_standardize.append(feature)

        scaler = StandardScaler()
        self.processed_data[[f'æ ‡å‡†åŒ–{feature}' for feature in features_to_standardize]] = scaler.fit_transform(
            self.processed_data[features_to_standardize]
        )

        # æ„å»ºç»¼åˆé£é™©æŒ‡æ•°
        risk_components = []
        if 'æ ‡å‡†åŒ–å¹´é¾„' in self.processed_data.columns:
            risk_components.append(self.processed_data['æ ‡å‡†åŒ–å¹´é¾„'] * 0.3)
        if 'æ ‡å‡†åŒ–å­•å¦‡BMI' in self.processed_data.columns:
            risk_components.append(self.processed_data['æ ‡å‡†åŒ–å­•å¦‡BMI'] * 0.3)
        if 'æ ‡å‡†åŒ–æ£€æµ‹æŠ½è¡€æ¬¡æ•°' in self.processed_data.columns:
            risk_components.append(self.processed_data['æ ‡å‡†åŒ–æ£€æµ‹æŠ½è¡€æ¬¡æ•°'] * 0.2)
        if 'æ ‡å‡†åŒ–æ£€æµ‹å­•å‘¨æ•°' in self.processed_data.columns:
            risk_components.append(-self.processed_data['æ ‡å‡†åŒ–æ£€æµ‹å­•å‘¨æ•°'] * 0.4)

        if risk_components:
            self.processed_data['ç»¼åˆé£é™©æŒ‡æ•°'] = sum(risk_components)

    def descriptive_analysis(self):
        """æè¿°æ€§ç»Ÿè®¡åˆ†æ"""
        if self.processed_data is None:
            self.feature_engineering()

        print("=== æ•°æ®åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ ===")
        key_features = ['å¹´é¾„', 'å­•å¦‡BMI', 'æ£€æµ‹å­•å‘¨æ•°', 'YæŸ“è‰²ä½“æµ“åº¦', 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°', 'æ€€å­•æ¬¡æ•°', 'ç”Ÿäº§æ¬¡æ•°']
        available_features = [f for f in key_features if f in self.processed_data.columns]
        print(self.processed_data[available_features].describe())

        # è®¡ç®—æ€»ä½“è¾¾æ ‡ç‡
        overall_rate = self.processed_data['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].mean()
        print(f"\næ€»ä½“YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡ç‡: {overall_rate:.2%}")

        # è®¡ç®—è¯¯å·®å½±å“
        error_impact = abs(self.processed_data['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].mean() -
                           self.processed_data['YæŸ“è‰²ä½“æµ“åº¦è¯¯å·®è¾¾æ ‡'].mean())
        print(f"æ£€æµ‹è¯¯å·®å¯¹è¾¾æ ‡ç‡çš„å½±å“: {error_impact:.2%}")

        # IVFå¦Šå¨ ä¸éIVFå¦Šå¨ çš„è¾¾æ ‡ç‡æ¯”è¾ƒ
        if 'IVFå¦Šå¨ ' in self.processed_data.columns:
            ivf_comparison = self.processed_data.groupby('IVFå¦Šå¨ ')['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].agg(
                æ ·æœ¬æ•°='count', è¾¾æ ‡ç‡='mean').reset_index()
            print("\nIVFå¦Šå¨ ä¸éIVFå¦Šå¨ çš„è¾¾æ ‡ç‡æ¯”è¾ƒ:")
            print(ivf_comparison)

        # èƒå„¿å¥åº·çŠ¶å†µä¸è¾¾æ ‡ç‡çš„å…³ç³»
        if 'èƒå„¿æ˜¯å¦å¥åº·' in self.processed_data.columns:
            health_comparison = self.processed_data.groupby('èƒå„¿æ˜¯å¦å¥åº·')['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].agg(
                æ ·æœ¬æ•°='count', è¾¾æ ‡ç‡='mean').reset_index()
            print("\nèƒå„¿å¥åº·çŠ¶å†µä¸è¾¾æ ‡ç‡çš„å…³ç³»:")
            print(health_comparison)

    def multi_factor_analysis(self):
        """å¤šå› ç´ åˆ†æ"""
        if self.processed_data is None:
            self.feature_engineering()

        # æŒ‰å¹´é¾„åˆ†ç»„ç»Ÿè®¡è¾¾æ ‡ç‡
        age_stats = self.processed_data.groupby('å¹´é¾„åˆ†ç»„')['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].agg(
            æ ·æœ¬æ•°='count', è¾¾æ ‡æ•°='sum', è¾¾æ ‡ç‡='mean').reset_index()

        # æŒ‰BMIåˆ†ç»„ç»Ÿè®¡è¾¾æ ‡ç‡
        bmi_stats = self.processed_data.groupby('BMIåˆ†ç»„')['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].agg(
            æ ·æœ¬æ•°='count', è¾¾æ ‡æ•°='sum', è¾¾æ ‡ç‡='mean').reset_index()

        # æŒ‰å­•å‘¨åˆ†ç»„ç»Ÿè®¡è¾¾æ ‡ç‡
        week_stats = self.processed_data.groupby('æ£€æµ‹å­•å‘¨æ•°')['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].agg(
            æ ·æœ¬æ•°='count', è¾¾æ ‡æ•°='sum', è¾¾æ ‡ç‡='mean').reset_index()

        # æŒ‰æ£€æµ‹æŠ½è¡€æ¬¡æ•°ç»Ÿè®¡è¾¾æ ‡ç‡
        blood_stats = None
        if 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°' in self.processed_data.columns:
            blood_stats = self.processed_data.groupby('æ£€æµ‹æŠ½è¡€æ¬¡æ•°')['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].agg(
                æ ·æœ¬æ•°='count', è¾¾æ ‡æ•°='sum', è¾¾æ ‡ç‡='mean').reset_index()

        # æŒ‰IVFå¦Šå¨ çŠ¶æ€ç»Ÿè®¡è¾¾æ ‡ç‡
        ivf_stats = None
        if 'IVFå¦Šå¨ ' in self.processed_data.columns:
            ivf_stats = self.processed_data.groupby('IVFå¦Šå¨ ')['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].agg(
                æ ·æœ¬æ•°='count', è¾¾æ ‡æ•°='sum', è¾¾æ ‡ç‡='mean').reset_index()

        return age_stats, bmi_stats, week_stats, blood_stats, ivf_stats

    def predict_optimal_time(self):
        """ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹æœ€ä½³æ£€æµ‹æ—¶é—´"""
        if self.processed_data is None:
            self.feature_engineering()

        # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
        base_features = ['å¹´é¾„', 'å­•å¦‡BMI', 'æ£€æµ‹å­•å‘¨æ•°']

        additional_features = ['æ£€æµ‹æŠ½è¡€æ¬¡æ•°', 'æ€€å­•æ¬¡æ•°', 'ç”Ÿäº§æ¬¡æ•°']
        for feature in additional_features:
            if feature in self.processed_data.columns:
                base_features.append(feature)

        # æ·»åŠ ç¼–ç åçš„åˆ†ç±»ç‰¹å¾
        encoded_features = [col for col in self.processed_data.columns if col.endswith('_ç¼–ç ')]
        base_features.extend(encoded_features)

        # æ·»åŠ æŸ“è‰²ä½“ç›¸å…³æŒ‡æ ‡
        chromosome_features = ['YæŸ“è‰²ä½“çš„Zå€¼', 'XæŸ“è‰²ä½“çš„Zå€¼', 'GCå«é‡']
        for feature in chromosome_features:
            if feature in self.processed_data.columns and not pd.api.types.is_categorical_dtype(
                    self.processed_data[feature]):
                base_features.append(feature)

        # è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„ç‰¹å¾
        available_features = [f for f in base_features if f in self.processed_data.columns]
        X = self.processed_data[available_features]
        y = self.processed_data['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡']

        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

        # è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹
        self.logreg_model = LogisticRegression(random_state=42, max_iter=1000)
        self.logreg_model.fit(X_train, y_train)

        # è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
        self.rf_model = RandomForestClassifier(random_state=42, n_estimators=100)
        self.rf_model.fit(X_train, y_train)

        # æ¨¡å‹è¯„ä¼°
        logreg_pred = self.logreg_model.predict(X_test)
        self.logreg_report = classification_report(y_test, logreg_pred)
        print("\n=== é€»è¾‘å›å½’æ¨¡å‹è¯„ä¼° ===")
        print(self.logreg_report)

        # è·å–éšæœºæ£®æ—çš„ç‰¹å¾é‡è¦æ€§
        self.feature_importance = pd.DataFrame({
            'ç‰¹å¾': available_features,
            'é‡è¦æ€§': self.rf_model.feature_importances_
        }).sort_values('é‡è¦æ€§', ascending=False)

        print("\nç‰¹å¾é‡è¦æ€§æ’åº (åŸºäºéšæœºæ£®æ—):")
        print(self.feature_importance)

        # åˆ›å»ºé¢„æµ‹å‡½æ•°
        def predict_pass_rate(input_features):
            weeks = np.arange(10, 26)
            predictions = []

            feature_dict = input_features.copy()

            for week in weeks:
                feature_dict['æ£€æµ‹å­•å‘¨æ•°'] = week
                feature_vector = [feature_dict.get(f, 0) for f in available_features]

                while len(feature_vector) < len(available_features):
                    feature_vector.append(0)
                feature_vector = feature_vector[:len(available_features)]

                prob = self.logreg_model.predict_proba([feature_vector])[0][1]
                predictions.append((week, prob))

            return predictions

        self.predict_pass_rate = predict_pass_rate

        return self.logreg_model, self.rf_model, self.predict_pass_rate, self.feature_importance, self.logreg_report

    def visualize_results(self, folder_path):
        """å¯è§†åŒ–åˆ†æç»“æœ"""
        if self.processed_data is None:
            self.feature_engineering()

        # ç¡®ä¿æ¨¡å‹å·²è®­ç»ƒ
        if not self.predict_pass_rate or self.feature_importance is None:
            self.predict_optimal_time()

        # è·å–åˆ†ææ•°æ®
        age_stats, bmi_stats, week_stats, blood_stats, ivf_stats = self.multi_factor_analysis()
        predict_pass_rate = self.predict_pass_rate
        feature_importance = self.feature_importance

        # åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        fig = plt.figure(figsize=(22, 20))

        # 1. å­•å‘¨ä¸YæŸ“è‰²ä½“æµ“åº¦çš„å…³ç³»æ•£ç‚¹å›¾
        ax1 = plt.subplot(4, 2, 1)
        sns.scatterplot(data=self.processed_data, x='æ£€æµ‹å­•å‘¨æ•°', y='YæŸ“è‰²ä½“æµ“åº¦', alpha=0.6)
        sns.regplot(data=self.processed_data, x='æ£€æµ‹å­•å‘¨æ•°', y='YæŸ“è‰²ä½“æµ“åº¦', scatter=False, color='red')
        plt.axhline(y=0.04, color='g', linestyle='--', label='è¾¾æ ‡é˜ˆå€¼(4%)')
        plt.title('å­•å‘¨ä¸YæŸ“è‰²ä½“æµ“åº¦çš„å…³ç³»')
        plt.xlabel('æ£€æµ‹å­•å‘¨')
        plt.ylabel('YæŸ“è‰²ä½“æµ“åº¦')
        plt.legend()

        # 2. å¹´é¾„åˆ†ç»„è¾¾æ ‡ç‡æŸ±çŠ¶å›¾
        ax2 = plt.subplot(4, 2, 2)
        sns.barplot(data=age_stats, x='å¹´é¾„åˆ†ç»„', y='è¾¾æ ‡ç‡', palette='Blues')
        for i, row in age_stats.iterrows():
            ax2.text(i, row['è¾¾æ ‡ç‡'] + 0.01, f"{row['è¾¾æ ‡ç‡']:.1%}", ha='center')
        plt.title('ä¸åŒå¹´é¾„ç»„çš„YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡ç‡')
        plt.xlabel('å¹´é¾„åˆ†ç»„')
        plt.ylabel('è¾¾æ ‡ç‡')
        plt.ylim(0, 1.1)

        # 3. BMIåˆ†ç»„è¾¾æ ‡ç‡æŸ±çŠ¶å›¾
        ax3 = plt.subplot(4, 2, 3)
        sns.barplot(data=bmi_stats, x='BMIåˆ†ç»„', y='è¾¾æ ‡ç‡', palette='Greens')
        for i, row in bmi_stats.iterrows():
            ax3.text(i, row['è¾¾æ ‡ç‡'] + 0.01, f"{row['è¾¾æ ‡ç‡']:.1%}", ha='center')
        plt.title('ä¸åŒBMIç»„çš„YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡ç‡')
        plt.xlabel('BMIåˆ†ç»„')
        plt.ylabel('è¾¾æ ‡ç‡')
        plt.ylim(0, 1.1)

        # 4. å­•å‘¨è¾¾æ ‡ç‡è¶‹åŠ¿å›¾
        ax4 = plt.subplot(4, 2, 4)
        sns.lineplot(data=week_stats, x='æ£€æµ‹å­•å‘¨æ•°', y='è¾¾æ ‡ç‡', marker='o', linewidth=2, label='è¾¾æ ‡ç‡è¶‹åŠ¿')
        plt.fill_between(week_stats['æ£€æµ‹å­•å‘¨æ•°'],
                         week_stats['è¾¾æ ‡ç‡'] - stats.sem(week_stats['è¾¾æ ‡ç‡']),
                         week_stats['è¾¾æ ‡ç‡'] + stats.sem(week_stats['è¾¾æ ‡ç‡']),
                         alpha=0.2, label='95%ç½®ä¿¡åŒºé—´')
        plt.title('ä¸åŒå­•å‘¨çš„YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡ç‡è¶‹åŠ¿')
        plt.xlabel('æ£€æµ‹å­•å‘¨')
        plt.ylabel('è¾¾æ ‡ç‡')
        plt.grid(True, linestyle='--', alpha=0.7)
        plt.legend()

        # 5. æ£€æµ‹æŠ½è¡€æ¬¡æ•°ä¸è¾¾æ ‡ç‡çš„å…³ç³»
        ax5 = plt.subplot(4, 2, 5)
        if blood_stats is not None:
            sns.barplot(data=blood_stats, x='æ£€æµ‹æŠ½è¡€æ¬¡æ•°', y='è¾¾æ ‡ç‡', palette='Purples')
            for i, row in blood_stats.iterrows():
                ax5.text(i, row['è¾¾æ ‡ç‡'] + 0.01, f"{row['è¾¾æ ‡ç‡']:.1%}", ha='center')
            plt.title('æ£€æµ‹æŠ½è¡€æ¬¡æ•°ä¸YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡ç‡çš„å…³ç³»')
            plt.xlabel('æ£€æµ‹æŠ½è¡€æ¬¡æ•°')
            plt.ylabel('è¾¾æ ‡ç‡')
            plt.ylim(0, 1.1)
        else:
            ax5.text(0.5, 0.5, 'æ— æ£€æµ‹æŠ½è¡€æ¬¡æ•°æ•°æ®', ha='center', va='center', transform=ax5.transAxes)
            ax5.set_title('æ£€æµ‹æŠ½è¡€æ¬¡æ•°ä¸YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡ç‡çš„å…³ç³»')

        # 6. è¯¯å·®å½±å“å¯è§†åŒ–
        ax6 = plt.subplot(4, 2, 6)
        error_comparison = self.processed_data.groupby('æ£€æµ‹å­•å‘¨æ•°')[
            ['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡', 'YæŸ“è‰²ä½“æµ“åº¦è¯¯å·®è¾¾æ ‡']].mean().reset_index()
        error_comparison_melt = error_comparison.melt(id_vars='æ£€æµ‹å­•å‘¨æ•°',
                                                      value_vars=['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡', 'YæŸ“è‰²ä½“æµ“åº¦è¯¯å·®è¾¾æ ‡'],
                                                      var_name='ç±»å‹', value_name='è¾¾æ ‡ç‡')

        sns.lineplot(data=error_comparison_melt, x='æ£€æµ‹å­•å‘¨æ•°', y='è¾¾æ ‡ç‡', hue='ç±»å‹',
                     marker='o', linewidth=2,
                     palette={'YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡': 'blue', 'YæŸ“è‰²ä½“æµ“åº¦è¯¯å·®è¾¾æ ‡': 'orange'})

        plt.title('æ£€æµ‹è¯¯å·®å¯¹è¾¾æ ‡ç‡çš„å½±å“')
        plt.xlabel('æ£€æµ‹å­•å‘¨')
        plt.ylabel('è¾¾æ ‡ç‡')

        handles, labels = ax6.get_legend_handles_labels()
        plt.legend(handles=handles[:2], labels=['å®é™…è¾¾æ ‡ç‡', 'è€ƒè™‘5%è¯¯å·®åè¾¾æ ‡ç‡'], loc='best')

        # 7. ç‰¹å¾é‡è¦æ€§å›¾
        ax7 = plt.subplot(4, 2, 7)
        top_n = min(10, len(feature_importance))
        sns.barplot(data=feature_importance.head(top_n), y='ç‰¹å¾', x='é‡è¦æ€§', palette='Oranges')
        plt.title('å½±å“YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡çš„é‡è¦å› ç´ ')
        plt.xlabel('é‡è¦æ€§å¾—åˆ†')
        plt.ylabel('ç‰¹å¾')
        plt.yticks(rotation=15)

        # 8. ä¸åŒäººç¾¤çš„æœ€ä½³æ£€æµ‹æ—¶é—´é¢„æµ‹
        ax8 = plt.subplot(4, 2, 8)

        # æ¨¡æ‹Ÿä¸åŒäººç¾¤çš„é¢„æµ‹ç»“æœ
        populations = [
            {'å¹´é¾„': 25, 'å­•å¦‡BMI': 22, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 1, 'æ€€å­•æ¬¡æ•°': 1, 'ç”Ÿäº§æ¬¡æ•°': 0, 'æ ‡ç­¾': 'å¹´è½»æ­£å¸¸BMIåˆäº§å¦‡'},
            {'å¹´é¾„': 35, 'å­•å¦‡BMI': 22, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 1, 'æ€€å­•æ¬¡æ•°': 2, 'ç”Ÿäº§æ¬¡æ•°': 1, 'æ ‡ç­¾': 'é«˜é¾„æ­£å¸¸BMIç»äº§å¦‡'},
            {'å¹´é¾„': 25, 'å­•å¦‡BMI': 30, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 1, 'æ€€å­•æ¬¡æ•°': 1, 'ç”Ÿäº§æ¬¡æ•°': 0, 'æ ‡ç­¾': 'å¹´è½»è‚¥èƒ–åˆäº§å¦‡'},
            {'å¹´é¾„': 35, 'å­•å¦‡BMI': 30, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 2, 'æ€€å­•æ¬¡æ•°': 3, 'ç”Ÿäº§æ¬¡æ•°': 1, 'æ ‡ç­¾': 'é«˜é¾„è‚¥èƒ–å¤šäº§å¦‡'}
        ]

        # ä¸ºæ¯ä¸ªç¾¤ä½“é¢„æµ‹è¾¾æ ‡æ¦‚ç‡
        for i, pop in enumerate(populations):
            predictions = predict_pass_rate(pop)
            if predictions:
                weeks, rates = zip(*predictions)
                markers = ['o', 's', '^', 'D']
                ax8.plot(weeks, rates, marker=markers[i], label=pop['æ ‡ç­¾'])

                optimal_week = weeks[np.argmax(rates)]
                optimal_rate = max(rates)

                offset_x = 0.5 if i % 2 == 0 else -2.5
                offset_y = 0.05 if i < 2 else -0.15

                ax8.annotate(f'æœ€ä½³: {optimal_week}å‘¨',
                             xy=(optimal_week, optimal_rate),
                             xytext=(optimal_week + offset_x, optimal_rate + offset_y),
                             arrowprops=dict(facecolor='black', shrink=0.05, width=1.5))

        plt.axhline(y=0.8, color='r', linestyle='--', alpha=0.5, label='80%ä¿¡å¿ƒé˜ˆå€¼')
        plt.title('ä¸åŒäººç¾¤çš„æœ€ä½³æ£€æµ‹æ—¶é—´é¢„æµ‹')
        plt.xlabel('æ£€æµ‹å­•å‘¨')
        plt.ylabel('é¢„æµ‹è¾¾æ ‡æ¦‚ç‡')
        plt.legend(loc='lower left', bbox_to_anchor=(0, 0))
        plt.grid(True, linestyle='--', alpha=0.7)
        plt.tight_layout(rect=[0, 0, 1, 0.95])
        plt.suptitle('ç”·èƒYæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´å¤šå› ç´ ç»¼åˆåˆ†æ', fontsize=16, y=1.02)

        # ä¿å­˜å›¾è¡¨
        img_path = os.path.join(folder_path, "YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´ç»¼åˆåˆ†æç»“æœ.png")
        plt.savefig(img_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³: {os.path.abspath(img_path)}")

    def save_processed_data(self, folder_path):
        """ä¿å­˜å¤„ç†åçš„å®Œæ•´æ•°æ®é›†"""
        if self.processed_data is None:
            self.feature_engineering()

        if not self.processed_data.empty:
            csv_path = os.path.join(folder_path, "processed_data.csv")
            self.processed_data.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"âœ… å¤„ç†åæ•°æ®å·²ä¿å­˜è‡³: {os.path.abspath(csv_path)}")
        else:
            print("âŒ æ— å¤„ç†åæ•°æ®å¯ä¿å­˜")

    def generate_conclusion(self, folder_path, age_stats, bmi_stats, week_stats, blood_stats, ivf_stats):
        """ç”Ÿæˆç»“æœæŠ¥å‘Šï¼ˆä»…åŒ…å«æ•°æ®ç»“æœå’Œè¿è¡Œæ—¥å¿—ï¼‰"""
        conclusion_path = os.path.join(folder_path, "conclusion.txt")

        # åŸºç¡€æ•°æ®æ”¶é›†
        total_samples = len(self.df) if not self.df.empty else 0
        processed_samples = len(self.processed_data) if not self.processed_data.empty else 0
        week_range = f"{self.df['æ£€æµ‹å­•å‘¨æ•°'].min()} - {self.df['æ£€æµ‹å­•å‘¨æ•°'].max()}å‘¨" if not self.df.empty else "æ— æ•°æ®"
        overall_rate = self.processed_data['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].mean() if not self.processed_data.empty else 0.0
        error_impact = abs(self.processed_data['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].mean() - self.processed_data[
            'YæŸ“è‰²ä½“æµ“åº¦è¯¯å·®è¾¾æ ‡'].mean()) if not self.processed_data.empty else 0.0

        # æ„å»ºæŠ¥å‘Šå†…å®¹
        conclusion_content = f"""# YæŸ“è‰²ä½“æµ“åº¦åˆ†æç»“æœæŠ¥å‘Š
{'=' * 60}

## ä¸€ã€æ•°æ®æ¦‚å†µ
- åŸå§‹æ•°æ®æ–‡ä»¶: {os.path.abspath(self.file_path)}
- åŸå§‹æ ·æœ¬æ€»é‡: {total_samples} ä¾‹
- ç­›é€‰åæ ·æœ¬é‡: {processed_samples} ä¾‹ï¼ˆ10-25å‘¨æ•°æ®ï¼‰
- æ£€æµ‹å­•å‘¨èŒƒå›´: {week_range}
- æ•°æ®æ—¶é—´èŒƒå›´: {self.df['æ£€æµ‹æ—¥æœŸ'].min().strftime('%Y-%m-%d') if 'æ£€æµ‹æ—¥æœŸ' in self.df.columns and not pd.isna(self.df['æ£€æµ‹æ—¥æœŸ'].min()) else 'æœªçŸ¥'} è‡³ {self.df['æ£€æµ‹æ—¥æœŸ'].max().strftime('%Y-%m-%d') if 'æ£€æµ‹æ—¥æœŸ' in self.df.columns and not pd.isna(self.df['æ£€æµ‹æ—¥æœŸ'].max()) else 'æœªçŸ¥'}

## äºŒã€æè¿°æ€§ç»Ÿè®¡ç»“æœ
### æ ¸å¿ƒæŒ‡æ ‡ç»Ÿè®¡
"""

        # æ·»åŠ å…³é”®æŒ‡æ ‡æè¿°æ€§ç»Ÿè®¡
        key_features = ['å¹´é¾„', 'å­•å¦‡BMI', 'æ£€æµ‹å­•å‘¨æ•°', 'YæŸ“è‰²ä½“æµ“åº¦', 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°', 'æ€€å­•æ¬¡æ•°', 'ç”Ÿäº§æ¬¡æ•°']
        available_features = [f for f in key_features if f in self.processed_data.columns]
        if available_features:
            desc_stats = self.processed_data[available_features].describe().round(3)
            conclusion_content += f"\n{desc_stats.to_string()}\n"
        else:
            conclusion_content += "\næ— å¯ç”¨å…³é”®æŒ‡æ ‡ç»Ÿè®¡æ•°æ®\n"

        conclusion_content += f"""
### è¾¾æ ‡æƒ…å†µç»Ÿè®¡
- YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ ‡å‡†: æµ“åº¦ â‰¥ 0.04
- æ€»ä½“è¾¾æ ‡ç‡: {overall_rate:.2%}ï¼ˆ{int(overall_rate * processed_samples)} ä¾‹è¾¾æ ‡ / {processed_samples} ä¾‹æ€»æ ·æœ¬ï¼‰
- æ£€æµ‹è¯¯å·®å½±å“: {error_impact:.2%}

### åˆ†ç»„è¾¾æ ‡ç‡æ•°æ®
#### IVFå¦Šå¨ ä¸éIVFå¦Šå¨ å¯¹æ¯”
"""

        if ivf_stats is not None and not ivf_stats.empty:
            conclusion_content += f"\n{ivf_stats.to_string(index=False, float_format=lambda x: f'{x:.2%}')}\n"
        else:
            conclusion_content += "\næ— IVFå¦Šå¨ ç›¸å…³æ•°æ®\n"

        conclusion_content += f"""
#### èƒå„¿å¥åº·çŠ¶å†µå¯¹æ¯”
"""

        if 'èƒå„¿æ˜¯å¦å¥åº·' in self.processed_data.columns:
            health_stats = self.processed_data.groupby('èƒå„¿æ˜¯å¦å¥åº·')['YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡'].agg(
                æ ·æœ¬æ•°='count', è¾¾æ ‡ç‡='mean').reset_index()
            conclusion_content += f"\n{health_stats.to_string(index=False, float_format=lambda x: f'{x:.2%}')}\n"
        else:
            conclusion_content += "\næ— èƒå„¿å¥åº·çŠ¶å†µç›¸å…³æ•°æ®\n"

        conclusion_content += f"""
## ä¸‰ã€å¤šå› ç´ åˆ†ææ•°æ®
### å¹´é¾„åˆ†ç»„è¾¾æ ‡ç‡
"""

        if not age_stats.empty:
            conclusion_content += f"\n{age_stats.to_string(index=False, float_format=lambda x: f'{x:.2%}')}\n"
        else:
            conclusion_content += "\næ— å¹´é¾„åˆ†ç»„è¾¾æ ‡ç‡æ•°æ®\n"

        conclusion_content += f"""
### BMIåˆ†ç»„è¾¾æ ‡ç‡
"""

        if not bmi_stats.empty:
            conclusion_content += f"\n{bmi_stats.to_string(index=False, float_format=lambda x: f'{x:.2%}')}\n"
        else:
            conclusion_content += "\næ— BMIåˆ†ç»„è¾¾æ ‡ç‡æ•°æ®\n"

        conclusion_content += f"""
### å­•å‘¨è¶‹åŠ¿è¾¾æ ‡ç‡
"""

        if not week_stats.empty:
            conclusion_content += f"\n{week_stats.to_string(index=False, float_format=lambda x: f'{x:.2%}')}\n"
        else:
            conclusion_content += "\næ— å­•å‘¨è¾¾æ ‡ç‡è¶‹åŠ¿æ•°æ®\n"

        conclusion_content += f"""
### æ£€æµ‹æŠ½è¡€æ¬¡æ•°å½±å“
"""

        if blood_stats is not None and not blood_stats.empty:
            conclusion_content += f"\n{blood_stats.to_string(index=False, float_format=lambda x: f'{x:.2%}')}\n"
        else:
            conclusion_content += "\næ— æ£€æµ‹æŠ½è¡€æ¬¡æ•°ç›¸å…³æ•°æ®\n"

        conclusion_content += f"""
## å››ã€æœºå™¨å­¦ä¹ æ¨¡å‹ç»“æœ
### é€»è¾‘å›å½’æ¨¡å‹è¯„ä¼°æŠ¥å‘Š
{self.logreg_report if self.logreg_report else 'æ¨¡å‹æœªè®­ç»ƒï¼Œæ— è¯„ä¼°æŠ¥å‘Š'}

### ç‰¹å¾é‡è¦æ€§æ’åºï¼ˆéšæœºæ£®æ—æ¨¡å‹ï¼‰
"""

        if self.feature_importance is not None and not self.feature_importance.empty:
            top_features = self.feature_importance.head(10).round(4)
            conclusion_content += f"\n{top_features.to_string(index=False)}\n"
        else:
            conclusion_content += "\næ— ç‰¹å¾é‡è¦æ€§æ•°æ®\n"

        conclusion_content += f"""
## äº”ã€å…¸å‹äººç¾¤é¢„æµ‹ç»“æœ
1. å¹´è½»æ­£å¸¸BMIåˆäº§å¦‡: æœ€ä½³æ£€æµ‹å­•å‘¨ {self._get_optimal_week({'å¹´é¾„': 25, 'å­•å¦‡BMI': 22, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 1, 'æ€€å­•æ¬¡æ•°': 1, 'ç”Ÿäº§æ¬¡æ•°': 0})} å‘¨ï¼ˆé¢„æµ‹è¾¾æ ‡ç‡ {self._get_optimal_rate({'å¹´é¾„': 25, 'å­•å¦‡BMI': 22, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 1, 'æ€€å­•æ¬¡æ•°': 1, 'ç”Ÿäº§æ¬¡æ•°': 0}):.2%}ï¼‰
2. é«˜é¾„æ­£å¸¸BMIç»äº§å¦‡: æœ€ä½³æ£€æµ‹å­•å‘¨ {self._get_optimal_week({'å¹´é¾„': 35, 'å­•å¦‡BMI': 22, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 1, 'æ€€å­•æ¬¡æ•°': 2, 'ç”Ÿäº§æ¬¡æ•°': 1})} å‘¨ï¼ˆé¢„æµ‹è¾¾æ ‡ç‡ {self._get_optimal_rate({'å¹´é¾„': 35, 'å­•å¦‡BMI': 22, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 1, 'æ€€å­•æ¬¡æ•°': 2, 'ç”Ÿäº§æ¬¡æ•°': 1}):.2%}ï¼‰
3. å¹´è½»è‚¥èƒ–åˆäº§å¦‡: æœ€ä½³æ£€æµ‹å­•å‘¨ {self._get_optimal_week({'å¹´é¾„': 25, 'å­•å¦‡BMI': 30, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 1, 'æ€€å­•æ¬¡æ•°': 1, 'ç”Ÿäº§æ¬¡æ•°': 0})} å‘¨ï¼ˆé¢„æµ‹è¾¾æ ‡ç‡ {self._get_optimal_rate({'å¹´é¾„': 25, 'å­•å¦‡BMI': 30, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 1, 'æ€€å­•æ¬¡æ•°': 1, 'ç”Ÿäº§æ¬¡æ•°': 0}):.2%}ï¼‰
4. é«˜é¾„è‚¥èƒ–å¤šäº§å¦‡: æœ€ä½³æ£€æµ‹å­•å‘¨ {self._get_optimal_week({'å¹´é¾„': 35, 'å­•å¦‡BMI': 30, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 2, 'æ€€å­•æ¬¡æ•°': 3, 'ç”Ÿäº§æ¬¡æ•°': 1})} å‘¨ï¼ˆé¢„æµ‹è¾¾æ ‡ç‡ {self._get_optimal_rate({'å¹´é¾„': 35, 'å­•å¦‡BMI': 30, 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°': 2, 'æ€€å­•æ¬¡æ•°': 3, 'ç”Ÿäº§æ¬¡æ•°': 1}):.2%}ï¼‰

## å…­ã€è¾“å‡ºæ–‡ä»¶è¯´æ˜
åˆ†æç»“æœæ–‡ä»¶å­˜å‚¨äº {os.path.abspath(folder_path)}ï¼ŒåŒ…å«ï¼š
1. conclusion.txt - æœ¬æŠ¥å‘Šæ–‡ä»¶
2. processed_data.csv - å¤„ç†åçš„å®Œæ•´æ•°æ®é›†
3. YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´ç»¼åˆåˆ†æç»“æœ.png - å¯è§†åŒ–å›¾è¡¨

---
æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

        # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
        with open(conclusion_path, 'w', encoding='utf-8') as f:
            f.write(conclusion_content)
        print(f"âœ… ç»“æœæŠ¥å‘Šå·²ä¿å­˜è‡³: {os.path.abspath(conclusion_path)}")

    def _get_optimal_week(self, input_features):
        """è·å–ç‰¹å®šäººç¾¤çš„æœ€ä½³æ£€æµ‹å­•å‘¨"""
        if not self.predict_pass_rate:
            self.predict_optimal_time()
        predictions = self.predict_pass_rate(input_features)
        return int(max(predictions, key=lambda x: x[1])[0]) if predictions else "æœªçŸ¥"

    def _get_optimal_rate(self, input_features):
        """è·å–ç‰¹å®šäººç¾¤çš„æœ€ä½³è¾¾æ ‡ç‡"""
        if not self.predict_pass_rate:
            self.predict_optimal_time()
        predictions = self.predict_pass_rate(input_features)
        return round(max(predictions, key=lambda x: x[1])[1], 4) if predictions else 0.0


# ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´åˆ†ææµç¨‹
if __name__ == "__main__":
    # é…ç½®æ–‡ä»¶è·¯å¾„
    INPUT_FILE = r"é™„ä»¶.xlsx"
    RESULT_FOLDER = "Problem3 results"

    # åˆå§‹åŒ–ç¯å¢ƒ
    os.makedirs(RESULT_FOLDER, exist_ok=True)
    print(f"ğŸ“‚ å·²åˆ›å»º/ç¡®è®¤ç»“æœæ–‡ä»¶å¤¹: {os.path.abspath(RESULT_FOLDER)}")

    # æ•°æ®åŠ è½½ä¸åˆå§‹åŒ–
    print("\nğŸ” å¼€å§‹åŠ è½½æ•°æ®...")
    analyzer = YChromosomeAnalysis(INPUT_FILE)
    if analyzer.df.empty:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢")
        exit()
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼ˆåŸå§‹æ ·æœ¬æ•°ï¼š{len(analyzer.df)}ï¼‰")

    # æ‰§è¡Œæ ¸å¿ƒåˆ†ææµç¨‹
    print("\nğŸ“Š å¼€å§‹ç‰¹å¾å·¥ç¨‹ä¸æè¿°æ€§åˆ†æ...")
    analyzer.feature_engineering()
    analyzer.descriptive_analysis()

    print("\nğŸ’¾ ä¿å­˜å¤„ç†åæ•°æ®...")
    analyzer.save_processed_data(RESULT_FOLDER)

    print("\nğŸ¤– å¼€å§‹æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ...")
    analyzer.predict_optimal_time()

    print("\nğŸ“ˆ å¼€å§‹å¯è§†åŒ–åˆ†æ...")
    analyzer.visualize_results(RESULT_FOLDER)

    print("\nğŸ“ å¼€å§‹ç”Ÿæˆç»“æœæŠ¥å‘Š...")
    age_stats, bmi_stats, week_stats, blood_stats, ivf_stats = analyzer.multi_factor_analysis()
    analyzer.generate_conclusion(RESULT_FOLDER, age_stats, bmi_stats, week_stats, blood_stats, ivf_stats)

    # åˆ†æå®Œæˆæç¤º
    print(f"\n{'=' * 60}")
    print("ğŸ‰ æ‰€æœ‰åˆ†ææµç¨‹å®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœæ–‡ä»¶å·²é›†ä¸­ä¿å­˜è‡³ï¼š{os.path.abspath(RESULT_FOLDER)}")
    print("ğŸ“‹ è¾“å‡ºæ–‡ä»¶æ¸…å•ï¼š")
    print("  1. conclusion.txt - ç»“æœæŠ¥å‘Š")
    print("  2. processed_data.csv - å¤„ç†åçš„æ•°æ®é›†")
    print("  3. YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´ç»¼åˆåˆ†æç»“æœ.png - å¯è§†åŒ–å›¾è¡¨")
    print(f"{'=' * 60}")
